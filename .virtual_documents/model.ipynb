import os

get_ipython().run_line_magic("matplotlib", " inline")
import string
import sys
import seaborn as sn

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os

get_ipython().run_line_magic("matplotlib", " inline")
import string
import sys
from collections import deque

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

import statistics

sys.path.append("code/.")
from sklearn import datasets
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.metrics import make_scorer, mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.dummy import DummyClassifier, DummyRegressor
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.model_selection import (
    GridSearchCV,
    RandomizedSearchCV,
    cross_val_score,
    cross_validate,
    train_test_split,
)
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import average_precision_score
from catboost import CatBoostClassifier, CatBoostRegressor
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from xgboost import XGBClassifier, XGBRegressor
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.ensemble import StackingClassifier
import eli5


## Reading in data
os.chdir("/Users/matthewgillies/FantasyPreds2023")
data = pd.read_csv("data/full_data.csv", index_col = 0)
data.head()


## Checking for NA Values
data.isna().any()


## Visualizing rows with NA values. It is hypothesized that NA values come from players who retired throughout this 
## stretch or who just began playing. 
data[data['player_age'].isna()]


## Dropping NA rows
data = data.dropna()


data.isna().any()


data.shape


## Removing the year column as the model should not take the year into account for future predictions
data = data.drop(columns = 'year')


## Data splitting with 70/30 split
X = data.drop(columns = "fpoints_g")
y = data["fpoints_g"]
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 123)
X_train.head()


## Further inspecting the data
X_train.info()


X_train.describe()


## Analyzing correlations of features
corr_matrix = X_train.corr()
plt.figure(figsize = (100,100))
plt.rcParams.update({'font.size': 50})
sn.heatmap(corr_matrix, annot = True)


## Examining histograms and distributions of features
plt.rcParams.update({'font.size': 10})
X_train.hist(bins = 15, figsize = (18,18))


## Preprocessing
colnames = list(X_train.columns)


## setting category names for preprocessor
scaling_feats = colnames


## Creating column transformer
ct = make_column_transformer(
    (StandardScaler(), scaling_feats))

ct


# Fitting X_train with scaled values, transforming both X_train and X_test
transformed_X_train = ct.fit_transform(X_train)
transformed_X_test = ct.transform(X_test)


## Creating transformed data frames
X_train_transformed = pd.DataFrame(transformed_X_train, columns = colnames)
X_test_transformed = pd.DataFrame(transformed_X_test, columns = colnames)
X_train_transformed.head()


## Creating function that returns mean and sd of cv scores
def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):
    """
    Returns mean and std of cross validation

    Parameters
    ----------
    model :
        scikit-learn model
    X_train : numpy array or pandas DataFrame
        X in the training data
    y_train :
        y in the training data

    Returns
    ----------
        pandas Series with mean scores from cross_validation
    """

    scores = cross_validate(model, X_train, y_train, **kwargs)

    mean_scores = pd.DataFrame(scores).mean()
    std_scores = pd.DataFrame(scores).std()
    out_col = []

    for i in range(len(mean_scores)):
        out_col.append((f"%0.3f (+/- %0.3f)" % (mean_scores[i], std_scores[i])))

    return pd.Series(data=out_col, index=mean_scores.index)


## Performing regression with dummy regressor
s = "neg_mean_absolute_percentage_error"
results = {}
dc = DummyRegressor(strategy = "mean")
pipe = make_pipeline(ct, dc)
dc.fit(X_train, y_train)
results["dummy"] = mean_std_cross_val_scores(pipe, X_train, y_train, return_train_score = True, 
                                             scoring=s)
pd.DataFrame(results)


pipe_linear_test = make_pipeline(ct, Ridge())


## Performing hyperparameter optimization for alpha in ridge
param_grid_linear = {"ridge__alpha" : [0.001,0.01,0.1,1,10,100,1000]}
random_search_linear = RandomizedSearchCV(pipe_linear_test, param_grid_linear, n_iter = 100, cv = 5, n_jobs = -1,random_state = 123,
                                  scoring=s)
random_search_linear.fit(X_train, y_train)
results_lin = pd.DataFrame(random_search_linear.cv_results_).set_index("rank_test_score").sort_index()
results_lin.T



## Applying ridge model with alpha = 10
pipe_linear = make_pipeline(ct, Ridge(alpha = 10))
results["linear"] = mean_std_cross_val_scores(pipe_linear, X_train, y_train, return_train_score = True, scoring = "neg_mean_absolute_percentage_error")
pd.DataFrame(results)


## Creating pipelines for the three models
pipe_rf = make_pipeline(ct, RandomForestRegressor(random_state = 123, n_jobs = -1))
pipe_xg = make_pipeline(ct, XGBRegressor(random_state = 123, eval_metric = "logloss", verbosity = 0))
pipe_cat = make_pipeline(ct, CatBoostRegressor(verbose=0, random_state=123))



## Hyperparameter optimization for random forest regressor
param_grid_rf = {"randomforestregressor__max_depth" : [2,4,6,8,10,12,14,16,18,20],
               "randomforestregressor__n_estimators" : [2,4,6,8,10,12,14,16,18,20]}
random_search_rf = RandomizedSearchCV(pipe_rf, param_grid_rf, n_iter = 100, cv = 5, n_jobs = -1,random_state = 123,
                                  scoring = s)
random_search_rf.fit(X_train, y_train)
results_rf = pd.DataFrame(random_search_rf.cv_results_).set_index("rank_test_score").sort_index()
results_rf.T


results_rf.T.iloc[6][1]


pipe_rf1 = make_pipeline(ct, RandomForestRegressor(random_state = 123, n_jobs = -1, n_estimators = 16, max_depth = 2))
results["Random Forest"] = mean_std_cross_val_scores(pipe_rf1, X_train, y_train, return_train_score = True, scoring = s)
pd.DataFrame(results)


## hyperparameter optimization for XGBoost
param_grid_xgb = {"xgbregressor__max_depth" : [2,4,6,8,10,12,14,16,18,20],
               "xgbregressor__learning_rate" : [0.001,0.01,0.1,0.2,0.3,0.4]}
random_search_xgb = RandomizedSearchCV(pipe_xg, param_grid_xgb, n_iter = 40, cv = 5, n_jobs = -1,random_state = 123,
                                  scoring = s)
random_search_xgb.fit(X_train, y_train)
results_xgb = pd.DataFrame(random_search_xgb.cv_results_).set_index("rank_test_score").sort_index()
results_xgb.T


results_xgb.T.iloc[6][1]


pipe_xgb = make_pipeline(ct, XGBRegressor(random_state = 123, eval_metric = "logloss", verbosity = 0
                                        , max_depth = 20, learning_rate = 0.2))
results["XGB"] = mean_std_cross_val_scores(pipe_xgb, X_train, y_train, return_train_score = True, scoring = s)
pd.DataFrame(results)


# Hyperparameter optimization for CatBoost
param_grid_cat = {"catboostregressor__learning_rate" : [0.001,0.01,0.1,0.2],
                  "catboostregressor__n_estimators" : [10,50,100,200,300]}
random_search_cat = RandomizedSearchCV(pipe_cat, param_grid_cat, n_iter = 20, cv = 5, n_jobs = -1, random_state = 123,
                                      scoring = s)
random_search_cat.fit(X_train, y_train)
results_cat = pd.DataFrame(random_search_cat.cv_results_).set_index("rank_test_score").sort_index()
results_cat.T


results_cat.T.iloc[6][1]


pipe_catb = make_pipeline(ct, CatBoostRegressor(verbose=0, random_state=123, n_estimators = 300, learning_rate = 0.01))
results["CatBoost"] = mean_std_cross_val_scores(pipe_catb, X_train, y_train, return_train_score = True, scoring = s)
pd.DataFrame(results)   


## performing forward selection with Ridge to see if model accuracy can be improved
pipe_forward_ridge = make_pipeline(
    ct,
    SequentialFeatureSelector(Ridge(alpha = 10), 
                              direction="forward", 
                              n_features_to_select='auto', 
                              tol=None),
    Ridge(alpha = 10),
)


results["ridgeselected"] = mean_std_cross_val_scores(pipe_forward_ridge, X_train, y_train, return_train_score = True,
                                                    scoring = s)
pd.DataFrame(results)


pipe_opt = make_pipeline(ct, Ridge(alpha = 10))


pipe_opt.fit(X_train, y_train)
coeffs = pipe_opt.named_steps["ridge"].coef_
coeffs


pd.DataFrame(data=coeffs, index=X_train_transformed.columns, columns=["Coefficients"]).sort_values(by = "Coefficients")


pipe_opt.named_steps["ridge"].intercept_


pipe_opt.fit(X_train, y_train)
test_predict = pipe_opt.predict(X_test)
test_score = mean_absolute_percentage_error(y_test, pipe_opt.predict(X_test))
test_score


## Adding predictionns into dataset
y_test_df = pd.DataFrame(y_test)
y_test_df["pred_fpoints_g"] = test_predict.tolist()
y_test_df


y_test_df['rank'] = y_test_df['pred_fpoints_g'].rank(ascending=False)
y_test_df.sort_values(by = "rank", ascending = True)



